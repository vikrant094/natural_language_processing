{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\vikrant\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import nltk\n",
    "nltk.download('punkt') # one time execution\n",
    "import re\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['code', 'data']\n",
      "['geoffery_hinton.txt', 'ian_godfellow.txt', 'pieter-abbeel.txt']\n"
     ]
    }
   ],
   "source": [
    "print(os.listdir('../'))\n",
    "data_path = '../data'\n",
    "print(os.listdir(data_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"As part of this course by deeplearning.ai, hope to not just teach you the technical\\nideas in deep learning, but also introduce you to some of the people,\\nsome of the heroes in deep learning. The people that invented so many of these ideas that you learn about\\nin this course or in this specialization. In these videos, I hope to also\\nask these leaders of deep learning to give you career advice for\\nhow you can break into deep learning, for how you can do research or\\nfind a job in deep learning. As the first of this interview series, I am delighted to present to you\\nan interview with Geoffrey Hinton. Welcome Geoff, and thank you for\\ndoing this interview with deeplearning.ai. >> Thank you for inviting me. >> I think that at this point you more\\nthan anyone else on this planet has invented so\\nmany of the ideas behind deep learning. And a lot of people have been calling\\nyou the godfather of deep learning. Although it wasn't until we were chatting\\na few minutes ago, until I realized you think I'm the first one to call you\\nthat, which I'm quite happy to have done. But what I want to ask is,\\nmany people know you as a legend, I want to ask about your\\npersonal story behind the legend. So how did you get involved in, going way\\nback, how did you get involved in AI and machine learning and neural networks? >> So when I was at high school,\\nI had a classmate who was always better than me at everything,\\nhe was a brilliant mathematician. And he came into school one day and said,\\ndid you know the brain uses holograms? And I guess that was about 1966, and\\nI said, sort of what's a hologram? And he explained that in a hologram\\nyou can chop off half of it, and you still get the whole picture. And that memories in the brain might\\nbe distributed over the whole brain. And so I guess he'd read\\nabout Lashley's experiments, where you chop off bits\\nof a rat's brain and discover that it's very hard to find one\\nbit where it stores one particular memory. So that's what first got me interested\\nin how does the brain store memories. And then when I went to university, I started off studying physiology and\\nphysics. I think when I was at Cambridge, I was the only undergraduate\\ndoing physiology and physics. And then I gave up on that and tried to do philosophy, because I\\nthought that might give me more insight. But that seemed to me actually lacking in ways of distinguishing\\nwhen they said something false. And so then I switched to psychology. And in psychology they had very,\\nvery simple theories, and it seemed to me it was sort of hopelessly inadequate\\nto explaining what the brain was doing. So then I took some time off and\\nbecame a carpenter. And then I decided that I'd try AI,\\nand went of to Edinburgh, to study AI with Langer Higgins. And he had done very nice\\nwork on neural networks, and he'd just given up on neural networks, and\\nbeen very impressed by Winograd's thesis. So when I arrived he thought I was kind\\nof doing this old fashioned stuff, and I ought to start on symbolic AI. And we had a lot of fights about that, but\\nI just kept on doing what I believed in. >> And then what? >> I eventually got a PhD in AI, and\\nthen I couldn't get a job in Britain. But I saw this very nice advertisement for Sloan Fellowships in California,\\nand I managed to get one of those. And I went to California, and\\neverything was different there. So in Britain,\\nneural nets was regarded as kind of silly, and in California, Don Norman and David Rumelhart were very open\\nto ideas about neural nets. It was the first time I'd been somewhere\\nwhere thinking about how the brain works, and thinking about how that\\nmight relate to psychology, was seen as a very positive thing. And it was a lot of fun there, in particular collaborating\\nwith David Rumelhart was great. >> I see, great.\\nSo this was when you were at UCSD, and you and Rumelhart around what, 1982, wound up writing the seminal\\nbackprop paper, right? >> Actually,\\nit was more complicated than that. >> What happened? >> In, I think, early 1982, David Rumelhart and me, and Ron Williams, between us developed\\nthe backprop algorithm, it was mainly David Rumelhart's idea. We discovered later that many\\nother people had invented it. David Parker had invented, it probably\\nafter us, but before we'd published. Paul Werbos had published it already\\nquite a few years earlier, but nobody paid it much attention. And there were other people who'd\\ndeveloped very similar algorithms, it's not clear what's meant by backprop. But using the chain rule to get\\nderivatives was not a novel idea. >> I see, why do you think it\\nwas your paper that helped so much the community latch on to backprop? It feels like your paper marked\\nan infection in the acceptance of this algorithm, whoever accepted it. >> So we managed to get\\na paper into Nature in 1986. And I did quite a lot of political\\nwork to get the paper accepted. I figured out that one of the referees was\\nprobably going to be Stuart Sutherland, who was a well known\\npsychologist in Britain. And I went to talk to him for\\na long time, and explained to him exactly\\nwhat was going on. And he was very impressed by the fact that we showed that backprop could\\nlearn representations for words. And you could look at those\\nrepresentations, which are little vectors, and you could understand the meaning\\nof the individual features. So we actually trained it on little\\ntriples of words about family trees, like Mary has mother Victoria. And you'd give it the first two words, and\\nit would have to predict the last word. And after you trained it, you could see all sorts of features in the\\nrepresentations of the individual words. Like the nationality of the person there, what generation they were, which branch of\\nthe family tree they were in, and so on. That was what made Stuart Sutherland\\nreally impressed with it, and I think that's why the paper got accepted. >> Very early word embeddings,\\nand you're already seeing learned features of semantic meanings\\nemerge from the training algorithm. >> Yes, so from a psychologist's point of\\nview, what was interesting was it unified two completely different strands of\\nideas about what knowledge was like. So there was the old psychologist's\\nview that a concept is just a big bundle of features, and\\nthere's lots of evidence for that. And then there was the AI view of the\\ntime, which is a formal structurist view. Which was that a concept is how\\nit relates to other concepts. And to capture a concept, you'd have to\\ndo something like a graph structure or maybe a semantic net. And what this back propagation\\nexample showed was, you could give it the information that would go into a graph\\nstructure, or in this case a family tree. And it could convert that information into\\nfeatures in such a way that it could then use the features to derive new\\nconsistent information, ie generalize. But the crucial thing was this to and fro\\nbetween the graphical representation or the tree structured representation\\nof the family tree, and a representation of the people\\nas big feature vectors. And in fact that from the graph-like\\nrepresentation you could get feature vectors. And from the feature vectors, you could\\nget more of the graph-like representation. >> So this is 1986? In the early 90s, Bengio showed that\\nyou can actually take real data, you could take English text, and\\napply the same techniques there, and get embeddings for real words from English\\ntext, and that impressed people a lot. >> I guess recently we've been talking a\\nlot about how fast computers like GPUs and supercomputers that's\\ndriving deep learning. I didn't realize that back between 1986\\nand the early 90's, it sounds like between you and Benjio there was already\\nthe beginnings of this trend. >> Yes, it was a huge advance. In 1986, I was using a list machine which\\nwas less than a tenth of a mega flop. And by about 1993 or thereabouts,\\npeople were seeing ten mega flops. >> I see.\\n>> So there was a factor of 100, and that's the point at\\nwhich is was easy to use, because computers were\\njust getting faster. >> Over the past several decades,\\nyou've invented so many pieces of neural networks and\\ndeep learning. I'm actually curious,\\nof all of the things you've invented, which of the ones you're still\\nmost excited about today? >> So I think the most beautiful\\none is the work I do with Terry Sejnowski on Boltzmann machines. So we discovered there was this really, really simple learning algorithm\\nthat applied to great big density connected nets where you\\ncould only see a few of the nodes. So it would learn hidden representations\\nand it was a very simple algorithm. And it looked like the kind of thing you\\nshould be able to get in a brain because each synapse only needed to know\\nabout the behavior of the two neurons it was directly connected to. And the information that was\\npropagated was the same. There were two different phases,\\nwhich we called wake and sleep. But in the two different phases, you're propagating information\\nin just the same way. Where as in something like back\\npropagation, there's a forward pass and a backward pass, and\\nthey work differently. They're sending different\\nkinds of signals. So I think that's\\nthe most beautiful thing. And for many years it looked\\njust like a curiosity, because it looked like\\nit was much too slow. But then later on, I got rid of a little\\nbit of the beauty, and it started letting me settle down and just use one iteration,\\nin a somewhat simpler net. And that gave restricted\\nBoltzmann machines, which actually worked\\neffectively in practice. So in the Netflix competition,\\nfor example, restricted Boltzmann machines were one\\nof the ingredients of the winning entry. >> And in fact, a lot of the recent\\nresurgence of neural net and deep learning, starting about 2007,\\nwas the restricted Boltzmann machine, and derestricted Boltzmann machine\\nwork that you and your lab did. >> Yes so that's another of the pieces\\nof work I'm very happy with, the idea of that you could train your\\nrestricted Boltzmann machine, which just had one layer of hidden features and\\nyou could learn one layer of feature. And then you could treat those\\nfeatures as data and do it again, and then you could treat the new features\\nyou learned as data and do it again, as many times as you liked. So that was nice, it worked in practice. And then UY Tay realized that the whole\\nthing could be treated as a single model, but it was a weird kind of model. It was a model where at the top you had\\na restricted Boltzmann machine, but below that you had a Sigmoid belief\\nnet which was something that invented many years early. So it was a directed model and what we'd managed to come up with by\\ntraining these restricted Boltzmann machines was an efficient way of doing\\ninferences in Sigmoid belief nets. So, around that time, there were people doing neural nets,\\nwho would use densely connected nets, but didn't have any good ways of doing\\nprobabilistic imprints in them. And you had people doing graphical models,\\nunlike my children, who could do inference properly, but\\nonly in sparsely connected nets. And what we managed to show was\\nthe way of learning these deep belief nets so that there's an approximate\\nform of inference that's very fast, it's just hands in a single forward pass\\nand that was a very beautiful result. And you could guarantee that each time\\nyou learn that extra layer of features there was a band, each time you learned\\na new layer, you got a new band, and the new band was always\\nbetter than the old band. >> The variational bands,\\nshowing as you add layers. Yes, I remember that video. >> So that was the second thing\\nthat I was really excited about. And I guess the third thing was the work\\nI did with on variational methods. It turns out people in statistics\\nhad done similar work earlier, but we didn't know about that. So we managed to make EN work a whole lot better by showing\\nyou didn't need to do a perfect E step. You could do an approximate E step. And EN was a big algorithm in statistics. And we'd showed a big\\ngeneralization of it. And in particular, in 1993,\\nI guess, with Van Camp. I did a paper, with I think,\\nthe first variational Bayes paper, where we showed that you could actually\\ndo a version of Bayesian learning that was far more tractable, by\\napproximating the true posterior with a. And you could do that in neural net. And I was very excited by that. >> I see.\\nWow, right. Yep, I think I remember\\nall of these papers. You and Hinton, approximate Paper,\\nspent many hours reading over that. And I think some of\\nthe algorithms you use today, or some of the algorithms that lots of\\npeople use almost every day, are what, things like dropouts, or\\nI guess activations came from your group? >> Yes and no. So other people have thought\\nabout rectified linear units. And we actually did some work with\\nrestricted Boltzmann machines showing that a ReLU was almost exactly equivalent\\nto a whole stack of logistic units. And that's one of the things\\nthat helped ReLUs catch on. >> I was really curious about that. The value paper had a lot of\\nmath showing that this function can be approximated with this\\nreally complicated formula. Did you do that math so your paper would\\nget accepted into an academic conference, or did all that math really influence\\nthe development of max of 0 and x? >> That was one of the cases where\\nactually the math was important to the development of the idea. So I knew about rectified linear units,\\nobviously, and I knew about logistic units. And because of the work\\non Boltzmann machines, all of the basic work was\\ndone using logistic units. And so the question was, could the learning algorithm work in\\nsomething with rectified linear units? And by showing the rectified linear units\\nwere almost exactly equivalent to a stack of logistic units, we showed that\\nall the math would go through. >> I see. And it provided the inspiration for\\ntoday, tons of people use ReLU and it just works without-\\n>> Yeah. >> Without necessarily needing to\\nunderstand the same motivation. >> Yeah, one thing I noticed\\nlater when I went to Google. I guess in 2014, I gave a talk\\nat Google about using ReLUs and initializing with the identity matrix. because the nice thing about ReLUs is\\nthat if you keep replicating the hidden layers and\\nyou initialize with the identity, it just copies the pattern\\nin the layer below. And so I was showing that you could train\\nnetworks with 300 hidden layers and you could train them really efficiently\\nif you initialize with their identity. But I didn't pursue that any further and\\nI really regret not pursuing that. We published one paper with showing\\nyou could initialize an active showing you could initialize\\nrecurringness like that. But I should have pursued it further\\nbecause Later on these residual networks is really that kind of thing. >> Over the years I've heard\\nyou talk a lot about the brain. I've heard you talk about relationship\\nbeing backprop and the brain. What are your current thoughts on that? >> I'm actually working on\\na paper on that right now. I guess my main thought is this. If it turns out the back prop is a really\\ngood algorithm for doing learning. Then for sure evolution could've\\nfigured out how to prevent it. I mean you have cells that could\\nturn into either eyeballs or teeth. Now, if cells can do that, they can for\\nsure implement backpropagation and presumably this huge\\nselective pressure for it. So I think the neuroscientist idea that\\nit doesn't look plausible is just silly. There may be some subtle\\nimplementation of it. And I think the brain probably has\\nsomething that may not be exactly be backpropagation, but\\nit's quite close to it. And over the years, I've come up with a\\nnumber of ideas about how this might work. So in 1987, working with Jay McClelland, I came up with\\nthe recirculation algorithm, where the idea is you send\\ninformation round a loop. And you try to make it so that things don't change as\\ninformation goes around this loop. So the simplest version would be you\\nhave input units and hidden units, and you send information from the input to\\nthe hidden and then back to the input, and then back to the hidden and\\nthen back to the input and so on. And what you want,\\nyou want to train an autoencoder, but you want to train it without\\nhaving to do backpropagation. So you just train it to try and get rid\\nof all variation in the activities. So the idea is that the learning rule for synapse is change the weighting\\nproportion to the presynaptic input and in proportion to the rate of\\nchange at the post synaptic input. But in recirculation, you're trying\\nto make the post synaptic input, you're trying to make the old one\\nbe good and the new one be bad, so you're changing in that direction. We invented this algorithm before\\nneuroscientists come up with spike-timing-dependent plasticity. Spike-timing-dependent plasticity is\\nactually the same algorithm but the other way round, where the new thing is good and\\nthe old thing is bad in the learning rule. So you're changing the weighting\\nproportions to the preset outlook activity times the new person outlook\\nactivity minus the old one. Later on I realized in 2007,\\nthat if you took a stack of Restricted Boltzmann machines and\\nyou trained it up. After it was trained, you then had\\nexactly the right conditions for implementing backpropagation\\nby just trying to reconstruct. If you looked at the reconstruction era,\\nthat reconstruction era would actually tell you the derivative\\nof the discriminative performance. And at the first deep learning workshop\\nat in 2007, I gave a talk about that. That was almost completely ignored. Later on, Joshua Benjo,\\ntook up the idea and that's actually done quite\\na lot of more work on that. And I've been doing\\nmore work on it myself. And I think this idea that if you have\\na stack of autoencoders, then you can get derivatives by sending activity\\nbackwards and locate reconstructionaires, is a really interesting idea and\\nmay well be how the brain does it. >> One other topic that I know you follow\\nabout and that I hear you're still working on is how to deal with\\nmultiple time skills in deep learning? So, can you share your thoughts on that? >> Yes, so actually, that goes back to\\nmy first years of graduate student. The first talk I ever gave was about\\nusing what I called fast weights. So weights that adapt rapidly,\\nbut decay rapidly. And therefore can hold short term memory. And I showed in a very simple\\nsystem in 1973 that you could do true recursion with those weights. And what I mean by true recursion\\nis that the neurons that is used in representing things get re-used for\\nrepresenting things in the recursive core. And the weights that is used for actually knowledge get re-used\\nin the recursive core. And so that leads the question of\\nwhen you pop out your recursive core, how do you remember what it was\\nyou were in the middle of doing? Where's that memory? because you used the neurons for\\nthe recursive core. And the answer is you can put that\\nmemory into fast weights, and you can recover the activities\\nneurons from those fast weights. And more recently working with Jimmy Ba, we actually got a paper in it by using\\nfast weights for recursion like that. >> I see. >> So that was quite a big gap. The first model was\\nunpublished in 1973 and then Jimmy Ba's model was in 2015,\\nI think, or 2016. So it's about 40 years later. >> And, I guess,\\none other idea of Quite a few years now, over five years, I think is capsules,\\nwhere are you with that? >> Okay, so I'm back to\\nthe state I'm used to being in. Which is I have this idea I really\\nbelieve in and nobody else believes it. And I submit papers about it and\\nthey would get rejected. But I really believe in this idea and\\nI'm just going to keep pushing it. So it hinges on,\\nthere's a couple of key ideas. One is about how you represent\\nmulti dimensional entities, and you can represent multi-dimensional entities\\nby just a little backdoor activities. As long as you know\\nthere's any one of them. So the idea is in each region of\\nthe image, you'll assume there's at most, one of the particular kind of feature. And then you'll use a bunch of neurons,\\nand their activities will represent\\nthe different aspects to that feature, like within that region exactly\\nwhat are its x and y coordinates? What orientation is it at? How fast is it moving? What color is it? How bright is it? And stuff like that. So you can use a whole bunch of neurons\\nto represent different dimensions of the same thing. Provided there's only one of them. That's a very different way\\nof doing representation from what we're normally\\nused to in neuronettes. Normally in neuronettes,\\nwe just have a great big layer, and all the units go off and\\ndo whatever they do. But you don't think of bundling them\\nup into little groups that represent different coordinates of the same thing. So I think we should beat\\nthis extra structure. And then the other idea\\nthat goes with that. >> So this means in the truth\\nof the representation, you partition the representation. >> Yes.\\n>> To different subsets. >> Yes.\\n>> To represent, right, rather than- >> I call each of those subsets a capsule. >> I see. >> And the idea is a capsule is able to\\nrepresent an instance of a feature, but only one. And it represents all the different\\nproperties of that feature. It's a feature that has a lot\\nof properties as opposed to a normal neuron and a normal neuronette,\\nwhich has just one scale of property. >> Yeah, I see yep. >> And then what you can do if you've got\\nthat, is you can do something that normal neuronettes are very bad at, which is you\\ncan do what I call routine by agreement. So let's suppose you want\\nto do segmentation and you have something that might be a mouth\\nand something else that might be a nose. And you want to know if you should\\nput them together to make one thing. So the idea should have a capsule for a mouth that has\\nthe parameters of the mouth. And you have a capsule for a nose\\nthat has the parameters of the nose. And then to decipher whether\\nto put them together or not, you get each of them to vote for\\nwhat the parameters should be for a face. Now if the mouth and the nose are in\\nthe right spacial relationship, they will agree. So when you get two captures at one level\\nvoting for the same set of parameters at the next level up,\\nyou can assume they're probably right, because agreement in a high\\ndimensional space is very unlikely. And that's a very different\\nway of doing filtering, than what we normally use in neural nets. So I think this routing by agreement\\nis going to be crucial for getting neural nets to generalize\\nmuch better from limited data. I think it'd be very good at\\ngetting the changes in viewpoint, very good at doing segmentation. And I'm hoping it will be much more\\nstatistically efficient than what we currently do in neural nets. Which is, if you want to deal\\nwith changes in viewpoint, you just give it a whole bunch of changes\\nin view point and training on them all. >> I see, right, so rather than\\nFIFO learning, supervised learning, you can learn this in some different way. >> Well, I still plan to do it\\nwith supervised learning, but the mechanics of the forward\\npaths are very different. It's not a pure forward path in the sense\\nthat there's little bits of iteration going on, where you think you found\\na mouth and you think you found a nose. And use a little bit\\nof iteration to decide whether they should really\\ngo together to make a face. And you can do back props\\nfrom that iteration. So you can try and\\ndo it a little discriminatively, and we're working on that\\nnow at my group in Toronto. So I now have a little Google team\\nin Toronto, part of the Brain team. That's what I'm excited about right now. >> I see, great, yeah. Look forward to that paper\\nwhen that comes out. >> Yeah, if it comes out [LAUGH]. >> You worked in deep learning for\\nseveral decades. I'm actually really curious,\\nhow has your thinking, your understanding of AI\\nchanged over these years? >> So I guess a lot of my intellectual\\nhistory has been around back propagation, and how to use back propagation,\\nhow to make use of its power. So to begin with, in the mid 80s,\\nwe were using it for discriminative learning and\\nit was working well. I then decided, by the early 90s, that actually most human learning was\\ngoing to be unsupervised learning. And I got much more interested\\nin unsupervised learning, and that's when I worked on things\\nlike the Wegstein algorithm. >> And your comments at that time\\nreally influenced my thinking as well. So when I was leading Google Brain,\\nour first project spent a lot of work in unsupervised learning\\nbecause of your influence. >> Right, and I may have misled you. Because in the long run, I think unsupervised learning is\\ngoing to be absolutely crucial. But you have to sort of face reality. And what's worked over the last ten\\nyears or so is supervised learning. Discriminative training,\\nwhere you have labels, or you're trying to predict the next thing\\nin the series, so that acts as the label. And that's worked incredibly well. I still believe that unsupervised learning\\nis going to be crucial, and things will work incredibly much better than they do\\nnow when we get that working properly, but we haven't yet. >> Yeah, I think many of the senior\\npeople in deep learning, including myself,\\nremain very excited about it. It's just none of us really have\\nalmost any idea how to do it yet. Maybe you do, I don't feel like I do. >> Variational altering code is where\\nyou use the reparameterization tricks. Seemed to me like a really nice idea. And generative adversarial nets also\\nseemed to me to be a really nice idea. I think generative\\nadversarial nets are one of the sort of biggest ideas in\\ndeep learning that's really new. I'm hoping I can make\\ncapsules that successful, but right now generative adversarial nets,\\nI think, have been a big breakthrough. >> What happened to sparsity and\\nslow features, which were two of the other principles for\\nbuilding unsupervised models? I was never as big on\\nsparsity as you were, buddy. But slow features, I think, is a mistake. You shouldn't say slow. The basic idea is right, but you shouldn't\\ngo for features that don't change, you should go for\\nfeatures that change in predictable ways. So here's a sort of basic principle\\nabout how you model anything. You take your measurements,\\nand you're applying nonlinear transformations to your\\nmeasurements until you get to a representation as a state vector\\nin which the action is linear. So you don't just pretend it's linear\\nlike you do with common filters. But you actually find a transformation\\nfrom the observables to the underlying variables\\nwhere linear operations, like matrix multipliers on the underlying\\nvariables, will do the work. So for example,\\nif you want to change viewpoints. If you want to produce the image\\nfrom another viewpoint, what you should do is go from\\nthe pixels to coordinates. And once you got to\\nthe coordinate representation, which is a kind of thing I'm\\nhoping captures will find. You can then do a matrix multiplier\\nto change viewpoint, and then you can map it back to pixels. >> Right, that's why you did all that. >> I think that's a very,\\nvery general principle. >> That's why you did all that\\nwork on face synthesis, right? Where you take a face and compress it\\nto very low dimensional vector, and so you can fiddle with that and\\nget back other faces. >> I had a student who worked on that,\\nI didn't do much work on that myself. >> Now I'm sure you still\\nget asked all the time, if someone wants to break into deep\\nlearning, what should they do? So what advice would you have? I'm sure you've given a lot of advice to\\npeople in one on one settings, but for the global audience of\\npeople watching this video. What advice would you have for\\nthem to get into deep learning? >> Okay, so my advice is sort of read the\\nliterature, but don't read too much of it. So this is advice I got from my advisor,\\nwhich is very unlike what most people say. Most people say you should spend several\\nyears reading the literature and then you should start\\nworking on your own ideas. And that may be true for some researchers,\\nbut for creative researchers I think what you want to do is read\\na little bit of the literature. And notice something that you\\nthink everybody is doing wrong, I'm contrary in that sense. You look at it and\\nit just doesn't feel right. And then figure out how to do it right. And then when people tell you,\\nthat's no good, just keep at it. And I have a very good principle for\\nhelping people keep at it, which is either your intuitions\\nare good or they're not. If your intuitions are good,\\nyou should follow them and you'll eventually be successful. If your intuitions are not good,\\nit doesn't matter what you do. >> I see [LAUGH]. Inspiring advice, might as well go for it. >> You might as well\\ntrust your intuitions. There's no point not trusting them. >> I see, yeah. I usually advise people to not just read,\\nbut replicate published papers. And maybe that puts a natural\\nlimiter on how many you could do, because replicating results\\nis pretty time consuming. Yes, it's true that when you're\\ntrying to replicate a published you discover all over little\\ntricks necessary to make it work. The other advice I have is,\\nnever stop programming. Because if you give a student\\nsomething to do, if they're botching, they'll come back and say, it didn't work. And the reason it didn't work would\\nbe some little decision they made, that they didn't realize is crucial. And if you give it to a good student,\\nlike for example. You can give him anything and\\nhe'll come back and say, it worked. I remember doing this once,\\nand I said, but wait a minute. Since we last talked, I realized it couldn't possibly work for\\nthe following reason. And said, yeah, I realized that right\\naway, so I assumed you didn't mean that. >> [LAUGH] I see, yeah,\\nthat's great, yeah. Let's see, any other advice for people that want to break into AI and\\ndeep learning? >> I think that's basically, read enough\\nso you start developing intuitions. And then, trust your intuitions and\\ngo for it, don't be too worried if everybody\\nelse says it's nonsense. >> And I guess there's no way\\nto know if others are right or wrong when they say it's nonsense, but you\\njust have to go for it, and then find out. >> Right, but there is one thing, which\\nis, if you think it's a really good idea, and other people tell you\\nit's complete nonsense, then you know you're\\nreally on to something. So one example of that is when and\\nI first came up with variational methods. I sent mail explaining it to a former\\nstudent of mine called Peter Brown, who knew a lot about. And he showed it to people\\nwho worked with him, called the brothers,\\nthey were twins, I think. And he then told me later what they said,\\nand they said, either this guy's drunk,\\nor he's just stupid, so they really,\\nreally thought it was nonsense. Now, it could have been partly\\nthe way I explained it, because I explained it in intuitive terms. But when you have what you\\nthink is a good idea and other people think is complete rubbish,\\nthat's the sign of a really good idea. >> I see, and research topics, new grad students should\\nwork on capsules and maybe unsupervised learning, any other? >> One good piece of advice for\\nnew grad students is, see if you can find an advisor\\nwho has beliefs similar to yours. Because if you work on stuff that\\nyour advisor feels deeply about, you'll get a lot of good advice and\\ntime from your advisor. If you work on stuff your\\nadvisor's not interested in, all you'll get is, you get some advice,\\nbut it won't be nearly so useful. >> I see, and\\nlast one on advice for learners, how do you feel about people\\nentering a PhD program? Versus joining a top company,\\nor a top research group? >> Yeah, it's complicated,\\nI think right now, what's happening is, there aren't enough academics trained in\\ndeep learning to educate all the people that we need educated in universities. There just isn't the faculty\\nbandwidth there, but I think that's going to be temporary. I think what's happened is,\\nmost departments have been very slow to understand the kind of\\nrevolution that's going on. I kind of agree with you, that it's not\\nquite a second industrial revolution, but it's something on nearly that scale. And there's a huge sea change going on, basically because our relationship\\nto computers has changed. Instead of programming them,\\nwe now show them, and they figure it out. That's a completely different\\nway of using computers, and computer science departments are built\\naround the idea of programming computers. And they don't understand that sort of, this showing computers is going to\\nbe as big as programming computers. Except they don't understand that half the\\npeople in the department should be people who get computers to do\\nthings by showing them. So my department refuses to acknowledge\\nthat it should have lots and lots of people doing this. They think they got a couple,\\nmaybe a few more, but not too many. And in that situation, you have to remind the big companies\\nto do quite a lot of the training. So Google is now training people,\\nwe call brain residence, I suspect the universities\\nwill eventually catch up. >> I see, right, in fact, maybe a lot\\nof students have figured this out. A lot of top 50 programs,\\nover half of the applicants are actually wanting to work on showing,\\nrather than programming. Yeah, cool, yeah, in fact,\\nto give credit where it's due, whereas a deep learning AI is creating\\na deep learning specialization. As far as I know, their first deep\\nlearning MOOC was actually yours taught on Coursera, back in 2012, as well. And somewhat strangely, that's when you first published the RMS\\nalgorithm, which also is a rough. >> Right, yes, well, as you know, that was\\nbecause you invited me to do the MOOC. And then when I was very dubious about\\ndoing, you kept pushing me to do it, so it was very good that I did,\\nalthough it was a lot of work. >> Yes, and thank you for doing that,\\nI remember you complaining to me, how much work it was. And you staying out late at night,\\nbut I think many, many learners have benefited for your first MOOC, so\\nI'm very grateful to you for it, so. >> That's good, yeah\\n>> Yeah, over the years, I've seen you embroiled in debates\\nabout paradigms for AI, and whether there's been a paradigm shift for\\nAI. What are your,\\ncan you share your thoughts on that? >> Yes, happily, so I think that in\\nthe early days, back in the 50s, people like von Neumann and\\ndidn't believe in symbolic AI, they were far more inspired by the brain. Unfortunately, they both died much too\\nyoung, and their voice wasn't heard. And in the early days of AI, people were completely convinced that\\nthe representations you need for intelligence were symbolic\\nexpressions of some kind. Sort of cleaned up logic, where you could\\ndo nomeratonic things, and not quite logic, but something like logic, and that\\nthe essence of intelligence was reasoning. What's happened now is,\\nthere's a completely different view, which is that what a thought is, is just\\na great big vector of neural activity, so contrast that with a thought\\nbeing a symbolic expression. And I think the people who thought that\\nthoughts were symbolic expressions just made a huge mistake. What comes in is a string of words, and\\nwhat comes out is a string of words. And because of that, strings of words\\nare the obvious way to represent things. So they thought what must be in\\nbetween was a string of words, or something like a string of words. And I think what's in between is\\nnothing like a string of words. I think the idea that thoughts must be\\nin some kind of language is as silly as the idea that understanding\\nthe layout of a spatial scene must be in pixels, pixels come in. And if we could, if we had a dot\\nmatrix printer attached to us, then pixels would come out, but\\nwhat's in between isn't pixels. And so I think thoughts are just\\nthese great big vectors, and that big vectors have causal powers. They cause other big vectors, and that's utterly unlike the standard AI view\\nthat thoughts are symbolic expressions. >> I see, good, I guess AI is certainly coming round\\nto this new point of view these days. >> Some of it, I think a lot of people in AI still think\\nthoughts have to be symbolic expressions. >> Thank you very much for\\ndoing this interview. It was fascinating to hear how deep\\nlearning has evolved over the years, as well as how you're still helping drive\\nit into the future, so thank you, Jeff. >> Well, thank you for\\ngiving me this opportunity. >> Thank you.\""
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "text = open(os.path.join(data_path,'geoffery_hinton.txt'),'r').read()\n",
    "text\n",
    "replaced = re.sub('\\n', ' ', text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:NLP]",
   "language": "python",
   "name": "conda-env-NLP-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
