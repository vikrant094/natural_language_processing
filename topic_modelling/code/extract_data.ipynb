{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "import os\n",
    "def extract_data(data_path = r'E:\\sudeep_work\\NLP\\data',page_url='https://qz.com/africa/latest'):\n",
    "    page = requests.get(page_url) \n",
    "    soup = BeautifulSoup(page.content, 'html.parser')\n",
    "    weblinks = soup.find_all('article')\n",
    "    pagelinks = []\n",
    "    for link in weblinks[5:]:    \n",
    "        url = link.contents[0].find_all('a')[0]   \n",
    "        pagelinks.append('http://qz.com'+url.get('href'))\n",
    "    authorname = []\n",
    "    title = []\n",
    "    thearticle = []\n",
    "    print(len(pagelinks))\n",
    "    for link in pagelinks:    \n",
    "        # store the text for each article\n",
    "        paragraphtext = []    \n",
    "        # get url\n",
    "        url = link\n",
    "        # get page text\n",
    "        page = requests.get(url)\n",
    "        # parse with BFS\n",
    "        soup = BeautifulSoup(page.text, 'html.parser')    \n",
    "        # get author name, if there's a named author\n",
    "        try:\n",
    "            abody = soup.find(class_='d3284 africa').find('a')\n",
    "            aname = abody.get_text() \n",
    "        except:\n",
    "            aname = 'Anonymous'\n",
    "        # get article title\n",
    "        atitle = soup.find(class_=\"_21349 africa none _4ca8e\")\n",
    "        thetitle = atitle.get_text() \n",
    "        # get main article page\n",
    "        articlebody = soup.find(class_='_61c55')\n",
    "        # get text\n",
    "        articletext = soup.find_all('p')[8:]\n",
    "        # print text\n",
    "        for paragraph in articletext[:-1]:\n",
    "            # get the text only\n",
    "            text = paragraph.get_text()\n",
    "            paragraphtext.append(text)        \n",
    "        # combine all paragraphs into an article\n",
    "        thearticle.append(paragraphtext)\n",
    "        authorname.append(aname)\n",
    "        title.append(thetitle)\n",
    "    myarticle = [' '.join(article) for article in thearticle]\n",
    "\n",
    "    # save article data to file\n",
    "    data = {'Title':title, \n",
    "            'Author':authorname, \n",
    "            'PageLink':pagelinks, \n",
    "            'Article':myarticle, \n",
    "            'Date':datetime.now()}\n",
    "    oldnews = pd.DataFrame(columns = ['Title', 'Author', 'PageLink', 'Article', 'Date'])\n",
    "    news = pd.DataFrame(data=data)\n",
    "    cols = ['Title', 'Author', 'PageLink', 'Article', 'Date']\n",
    "    news = news[cols]\n",
    "    afronews = oldnews.append(news)\n",
    "    afronews.drop_duplicates(subset='Title', keep='last', inplace=True)\n",
    "    afronews.reset_index(inplace=True)\n",
    "    afronews.drop(labels='index', axis=1, inplace=True)\n",
    "    filename = os.path.join(data_path,'news_xlxs')\n",
    "    wks_name = 'Data'\n",
    "    writer = pd.ExcelWriter(filename)\n",
    "    afronews.to_excel(writer, wks_name, index=False)\n",
    "    writer.save()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:NLP]",
   "language": "python",
   "name": "conda-env-NLP-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
